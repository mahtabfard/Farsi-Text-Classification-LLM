{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8f9aSwWA8xR"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMXPz7V7A_i1",
        "outputId": "77840370-e378-408e-a8fc-c6be6d24a208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets accelerate peft sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syC6JjFTWuAx"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import json\n",
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding,\n",
        "    EarlyStoppingCallback\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiNJt3DZBLYc"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqJiUgReBO2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0d2eb08-337f-44e7-bb34-9a1d2619a153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_p9BI-lFz3H"
      },
      "source": [
        "# Testing The Model Before Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Klr36-d4HE6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2978f13d-7a78-412b-9c6c-5d6d65dba022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--HooshvareLab--bert-fa-base-uncased/snapshots/a04aa40c97bcdde570ae11986a534542c2995a62/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.53.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 100000\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--HooshvareLab--bert-fa-base-uncased/snapshots/a04aa40c97bcdde570ae11986a534542c2995a62/vocab.txt\n",
            "loading file tokenizer.json from cache at None\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at None\n",
            "loading file chat_template.jinja from cache at None\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--HooshvareLab--bert-fa-base-uncased/snapshots/a04aa40c97bcdde570ae11986a534542c2995a62/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.53.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 100000\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--HooshvareLab--bert-fa-base-uncased/snapshots/a04aa40c97bcdde570ae11986a534542c2995a62/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.53.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 100000\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--HooshvareLab--bert-fa-base-uncased/snapshots/a04aa40c97bcdde570ae11986a534542c2995a62/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"\\u0627\\u0642\\u062a\\u0635\\u0627\\u062f\\u06cc\",\n",
            "    \"1\": \"\\u062a\\u0641\\u0631\\u06cc\\u062d \\u0648 \\u0646\\u0634\\u0627\\u0637\",\n",
            "    \"2\": \"\\u0641\\u0631\\u0647\\u0646\\u06af\",\n",
            "    \"3\": \"\\u0648\\u0631\\u0632\\u0634\\u06cc\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"\\u0627\\u0642\\u062a\\u0635\\u0627\\u062f\\u06cc\": 0,\n",
            "    \"\\u062a\\u0641\\u0631\\u06cc\\u062d \\u0648 \\u0646\\u0634\\u0627\\u0637\": 1,\n",
            "    \"\\u0641\\u0631\\u0647\\u0646\\u06af\": 2,\n",
            "    \"\\u0648\\u0631\\u0632\\u0634\\u06cc\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.53.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 100000\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--HooshvareLab--bert-fa-base-uncased/snapshots/a04aa40c97bcdde570ae11986a534542c2995a62/pytorch_model.bin\n",
            "Attempting to create safetensors variant\n",
            "Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "لطفاً یک یا چند متن فارسی وارد کنید (برای پایان Enter خالی بزنید):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Safetensors PR exists\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "متن:  در پی نوسانات شدید بازار ارز و افزایش نرخ دلار در هفته‌های اخیر، بانک مرکزی با اتخاذ سیاست‌های جدیدی تلاش کرده است تا ثبات نسبی را به بازار ارز بازگرداند. در این راستا، عرضه ارز در سامانه نیما افزایش یافته و سقف خرید ارز برای واردکنندگان کاهش یافته است. همچنین، برنامه‌هایی برای مدیریت تقاضای ارز مسافرتی و تجاری در دست اجراست. کارشناسان معتقدند که تنها راهکار بلندمدت برای مهار تورم و کنترل نوسانات ارزی، تقویت تولید داخلی، جذب سرمایه‌گذاری خارجی و افزایش صادرات غیرنفتی است. در همین حال، بخش خصوصی نیز خواستار کاهش موانع تجاری و اصلاح ساختار بانکی برای تسهیل فعالیت‌های اقتصادی شده است.\n",
            "متن:  در مراسم افتتاحیه سی‌ونهمین جشنواره بین‌المللی فیلم فجر، که با حضور گسترده اهالی سینما، منتقدان و خبرنگاران برگزار شد، آثار شاخصی از سینماگران جوان و باتجربه به نمایش درآمد. امسال با توجه به تغییرات در آیین‌نامه داوری و افزایش تعداد فیلم‌های بخش مسابقه، تنوع بیشتری در ژانرها و سبک‌ها مشاهده می‌شود. همچنین، فیلم‌هایی با رویکرد اجتماعی و پرداختن به مسائل روز جامعه ایرانی بیشتر مورد توجه قرار گرفته‌اند. در حاشیه این مراسم، از چند هنرمند پیشکسوت نیز تقدیر به‌عمل آمد و نشستی با موضوع «سینما و هویت فرهنگی» برگزار شد. برگزارکنندگان جشنواره اعلام کردند که هدف امسال، تقویت تعامل فرهنگی با سینماهای منطقه و حمایت از تولیدات مستقل داخلی است.\n",
            "متن:  تیم ملی والیبال ایران در چهارمین دیدار خود از مرحله گروهی رقابت‌های لیگ ملت‌های ۲۰۲۵ به مصاف تیم قدرتمند ایتالیا رفت. این بازی که در سالن المپیک توکیو برگزار شد، با حضور پرشور تماشاگران و پخش زنده از چند شبکه تلویزیونی همراه بود. والیبالیست‌های ایرانی با بازی هماهنگ و دفاع منسجم، موفق شدند ست اول را با اختلاف امتیاز بالا به‌نفع خود به پایان برسانند. هرچند تیم ایتالیا در ست دوم بازگشتی قدرتمند داشت، اما در نهایت ایران با درخشش سعید معروف و امیر غفور، بازی را در ست پنجم با نتیجه ۳ بر ۲ به سود خود تمام کرد. سرمربی تیم ایران در پایان مسابقه از تعهد و انگیزه بازیکنانش تمجید کرد و وعده داد تیم با قدرت بیشتری در ادامه رقابت‌ها حاضر خواهد شد.\n",
            "متن:  در آستانه فصل تابستان، نمایشگاه گردشگری و صنایع‌دستی تهران با استقبال گسترده بازدیدکنندگان آغاز به‌کار کرد. در این نمایشگاه، استان‌های مختلف کشور با ارائه غرفه‌هایی متنوع، جاذبه‌های گردشگری، آیین‌های سنتی، غذاهای محلی و تولیدات صنایع‌دستی خود را معرفی کردند. یکی از بخش‌های جذاب نمایشگاه، اجرای زنده موسیقی نواحی، کارگاه‌های آموزشی سفال‌گری، فرش‌بافی و ساخت زیورآلات سنتی بود که توانست توجه خانواده‌ها و گردشگران را به خود جلب کند. مسئولان برگزارکننده هدف این رویداد را ترویج گردشگری داخلی، حمایت از مشاغل بومی و تقویت اقتصاد گردشگری اعلام کردند. همچنین، بسته‌های سفر تخفیفی نیز توسط آژانس‌های مسافرتی در اختیار بازدیدکنندگان قرار گرفت.\n",
            "متن: \n",
            "\n",
            "نتایج پیش‌بینی مدل خام:\n",
            "متن: در پی نوسانات شدید بازار ارز و افزایش نرخ دلار در هفته‌های اخیر، بانک مرکزی با اتخاذ سیاست‌های جدیدی تلاش کرده است تا ثبات نسبی را به بازار ارز بازگرداند. در این راستا، عرضه ارز در سامانه نیما افزایش یافته و سقف خرید ارز برای واردکنندگان کاهش یافته است. همچنین، برنامه‌هایی برای مدیریت تقاضای ارز مسافرتی و تجاری در دست اجراست. کارشناسان معتقدند که تنها راهکار بلندمدت برای مهار تورم و کنترل نوسانات ارزی، تقویت تولید داخلی، جذب سرمایه‌گذاری خارجی و افزایش صادرات غیرنفتی است. در همین حال، بخش خصوصی نیز خواستار کاهش موانع تجاری و اصلاح ساختار بانکی برای تسهیل فعالیت‌های اقتصادی شده است.\n",
            "دسته‌بندی پیش‌بینی‌شده: تفریح و نشاط (اطمینان: 35.58%)\n",
            "\n",
            "متن: در مراسم افتتاحیه سی‌ونهمین جشنواره بین‌المللی فیلم فجر، که با حضور گسترده اهالی سینما، منتقدان و خبرنگاران برگزار شد، آثار شاخصی از سینماگران جوان و باتجربه به نمایش درآمد. امسال با توجه به تغییرات در آیین‌نامه داوری و افزایش تعداد فیلم‌های بخش مسابقه، تنوع بیشتری در ژانرها و سبک‌ها مشاهده می‌شود. همچنین، فیلم‌هایی با رویکرد اجتماعی و پرداختن به مسائل روز جامعه ایرانی بیشتر مورد توجه قرار گرفته‌اند. در حاشیه این مراسم، از چند هنرمند پیشکسوت نیز تقدیر به‌عمل آمد و نشستی با موضوع «سینما و هویت فرهنگی» برگزار شد. برگزارکنندگان جشنواره اعلام کردند که هدف امسال، تقویت تعامل فرهنگی با سینماهای منطقه و حمایت از تولیدات مستقل داخلی است.\n",
            "دسته‌بندی پیش‌بینی‌شده: تفریح و نشاط (اطمینان: 37.31%)\n",
            "\n",
            "متن: تیم ملی والیبال ایران در چهارمین دیدار خود از مرحله گروهی رقابت‌های لیگ ملت‌های ۲۰۲۵ به مصاف تیم قدرتمند ایتالیا رفت. این بازی که در سالن المپیک توکیو برگزار شد، با حضور پرشور تماشاگران و پخش زنده از چند شبکه تلویزیونی همراه بود. والیبالیست‌های ایرانی با بازی هماهنگ و دفاع منسجم، موفق شدند ست اول را با اختلاف امتیاز بالا به‌نفع خود به پایان برسانند. هرچند تیم ایتالیا در ست دوم بازگشتی قدرتمند داشت، اما در نهایت ایران با درخشش سعید معروف و امیر غفور، بازی را در ست پنجم با نتیجه ۳ بر ۲ به سود خود تمام کرد. سرمربی تیم ایران در پایان مسابقه از تعهد و انگیزه بازیکنانش تمجید کرد و وعده داد تیم با قدرت بیشتری در ادامه رقابت‌ها حاضر خواهد شد.\n",
            "دسته‌بندی پیش‌بینی‌شده: تفریح و نشاط (اطمینان: 42.43%)\n",
            "\n",
            "متن: در آستانه فصل تابستان، نمایشگاه گردشگری و صنایع‌دستی تهران با استقبال گسترده بازدیدکنندگان آغاز به‌کار کرد. در این نمایشگاه، استان‌های مختلف کشور با ارائه غرفه‌هایی متنوع، جاذبه‌های گردشگری، آیین‌های سنتی، غذاهای محلی و تولیدات صنایع‌دستی خود را معرفی کردند. یکی از بخش‌های جذاب نمایشگاه، اجرای زنده موسیقی نواحی، کارگاه‌های آموزشی سفال‌گری، فرش‌بافی و ساخت زیورآلات سنتی بود که توانست توجه خانواده‌ها و گردشگران را به خود جلب کند. مسئولان برگزارکننده هدف این رویداد را ترویج گردشگری داخلی، حمایت از مشاغل بومی و تقویت اقتصاد گردشگری اعلام کردند. همچنین، بسته‌های سفر تخفیفی نیز توسط آژانس‌های مسافرتی در اختیار بازدیدکنندگان قرار گرفت.\n",
            "دسته‌بندی پیش‌بینی‌شده: تفریح و نشاط (اطمینان: 37.15%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# غیرفعال‌سازی W&B\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# لیبل‌ها (فارسی)\n",
        "labels_list = ['اقتصادی', 'تفریح و نشاط', 'فرهنگ', 'ورزشی']\n",
        "label2id = {label: i for i, label in enumerate(labels_list)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "\n",
        "# بارگذاری مدل خام و توکنایزر\n",
        "MODEL_NAME = \"HooshvareLab/bert-fa-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=len(labels_list),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "# دریافت ورودی از کاربر\n",
        "print(\"لطفاً یک یا چند متن فارسی وارد کنید (برای پایان Enter خالی بزنید):\")\n",
        "texts = []\n",
        "while True:\n",
        "    line = input(\"متن: \").strip()\n",
        "    if line == \"\":\n",
        "        break\n",
        "    texts.append(line)\n",
        "\n",
        "if not texts:\n",
        "    print(\"متنی وارد نشده.\")\n",
        "    exit()\n",
        "\n",
        "# پیش‌پردازش\n",
        "inputs = tokenizer(\n",
        "    texts,\n",
        "    return_tensors=\"pt\",\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=256\n",
        ")\n",
        "\n",
        "# پیش‌بینی\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    probs = torch.softmax(outputs.logits, dim=1)\n",
        "    preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "# چاپ نتایج\n",
        "print(\"\\nنتایج پیش‌بینی مدل خام:\")\n",
        "for i, text in enumerate(texts):\n",
        "    label = id2label[preds[i].item()]\n",
        "    confidence = probs[i][preds[i]].item()\n",
        "    print(f\"متن: {text}\")\n",
        "    print(f\"دسته‌بندی پیش‌بینی‌شده: {label} (اطمینان: {confidence:.2%})\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm4n7RP5WYTZ"
      },
      "source": [
        "# LORA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPMRIPXxYxr7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ==== تنظیمات ====\n",
        "MODEL_NAME = \"HooshvareLab/bert-fa-base-uncased\"\n",
        "TRAIN_FILE = \"/content/drive/MyDrive/Final/lora_train.json\"\n",
        "VAL_FILE = \"/content/drive/MyDrive/Final/lora_val.json\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Final/final-bert-fa-lora\"\n",
        "\n",
        "NUM_EPOCHS = 3\n",
        "BATCH_SIZE = 8\n",
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# ==== بارگذاری داده‌ها ====\n",
        "with open(TRAIN_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "    train_data = json.load(f)\n",
        "with open(VAL_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "    val_data = json.load(f)\n",
        "\n",
        "labels_list = sorted(list(set(item['label'] for item in train_data + val_data)))\n",
        "label2id = {label: i for i, label in enumerate(labels_list)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "NUM_LABELS = len(labels_list)\n",
        "\n",
        "# ==== لیبل‌های انگلیسی فقط برای نمایش در نمودار ====\n",
        "# ترتیب باید با labels_list یکسان باشد\n",
        "label_translation = {\n",
        "    'اقتصادی': 'Economic',\n",
        "    'تفریح و نشاط': 'Entertainment',\n",
        "    'فرهنگ': 'Culture',\n",
        "    'ورزشی': 'Sports'\n",
        "}\n",
        "labels_list_en = [label_translation[label] for label in labels_list]\n",
        "\n",
        "# ==== توکنایزر ====\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    text = examples[\"text\"]\n",
        "    labels = [label2id[label] for label in examples[\"label\"]]\n",
        "    encodings = tokenizer(\n",
        "        text,\n",
        "        max_length=256,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True\n",
        "    )\n",
        "    encodings[\"labels\"] = labels\n",
        "    return encodings\n",
        "\n",
        "train_dataset = Dataset.from_list(train_data).map(preprocess_function, batched=True)\n",
        "val_dataset = Dataset.from_list(val_data).map(preprocess_function, batched=True)\n",
        "\n",
        "train_dataset = train_dataset.remove_columns([\"text\", \"label\"])\n",
        "val_dataset = val_dataset.remove_columns([\"text\", \"label\"])\n",
        "\n",
        "# ==== مدل ====\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=NUM_LABELS,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "# ==== تابع متریک ====\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {'accuracy': acc}\n",
        "\n",
        "# ==== تنظیمات آموزش ====\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    logging_dir=f\"{OUTPUT_DIR}/logs\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    report_to=\"none\",\n",
        "    log_level=\"info\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    seed=SEED,\n",
        "    do_eval=True,\n",
        "    load_best_model_at_end=False,\n",
        "    disable_tqdm=False,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    greater_is_better=True\n",
        ")\n",
        "\n",
        "# ==== Trainer ====\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# ==== آموزش ====\n",
        "print(\"🚀 شروع آموزش مدل...\")\n",
        "trainer.train()\n",
        "\n",
        "# ==== ذخیره مدل ====\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "trainer.save_model(os.path.join(OUTPUT_DIR, \"best_model\"))\n",
        "print(\"✅ مدل با موفقیت ذخیره شد!\")\n",
        "\n",
        "# ==== پیش‌بینی و گزارش ====\n",
        "predictions = trainer.predict(val_dataset)\n",
        "preds = np.argmax(predictions.predictions, axis=1)\n",
        "labels = predictions.label_ids\n",
        "\n",
        "print(\"\\n📊 Classification Report:\")\n",
        "print(classification_report(labels, preds, target_names=labels_list))\n",
        "\n",
        "# ==== Confusion Matrix ====\n",
        "cm = confusion_matrix(labels, preds)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    xticklabels=labels_list_en,\n",
        "    yticklabels=labels_list_en,\n",
        "    cmap=\"Blues\",\n",
        "    linewidths=0.5,\n",
        "    linecolor='gray'\n",
        ")\n",
        "plt.xlabel(\"Predicted\", fontsize=12)\n",
        "plt.ylabel(\"True\", fontsize=12)\n",
        "plt.title(\"Confusion Matrix\", fontsize=14)\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"confusion_matrix.png\"))\n",
        "plt.show()\n",
        "\n",
        "# ==== ذخیره نتایج در فایل JSON ====\n",
        "results_data = {\n",
        "    \"train_loss\": float(trainer.state.log_history[-1][\"train_loss\"]) if \"train_loss\" in trainer.state.log_history[-1] else 0,\n",
        "    \"val_accuracy\": float(accuracy_score(labels, preds)),\n",
        "    \"classification_report\": classification_report(labels, preds, target_names=labels_list, output_dict=True),\n",
        "    \"confusion_matrix\": cm.tolist(),\n",
        "    \"labels\": labels_list\n",
        "}\n",
        "\n",
        "results_path = os.path.join(OUTPUT_DIR, \"results.json\")\n",
        "with open(results_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(results_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"✅ نتایج در مسیر زیر ذخیره شد: {results_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# ==== تنظیمات ====\n",
        "MODEL_NAME = \"HooshvareLab/bert-fa-base-uncased\"\n",
        "TRAIN_FILE = \"/content/drive/MyDrive/Final/lora_train.json\"\n",
        "VAL_FILE = \"/content/drive/MyDrive/Final/lora_val.json\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Final1/final-bert-fa-lora\"\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 8\n",
        "SEED = 42\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# ==== بارگذاری داده‌ها ====\n",
        "with open(TRAIN_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "    train_data = json.load(f)\n",
        "with open(VAL_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "    val_data = json.load(f)\n",
        "\n",
        "labels_list = sorted(list(set(item['label'] for item in train_data + val_data)))\n",
        "label2id = {label: i for i, label in enumerate(labels_list)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "NUM_LABELS = len(labels_list)\n",
        "\n",
        "label_translation = {\n",
        "    'اقتصادی': 'Economic',\n",
        "    'تفریح و نشاط': 'Entertainment',\n",
        "    'فرهنگ': 'Culture',\n",
        "    'ورزشی': 'Sports'\n",
        "}\n",
        "labels_list_en = [label_translation[label] for label in labels_list]\n",
        "\n",
        "# ==== توکنایزر ====\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    text = examples[\"text\"]\n",
        "    labels = [label2id[label] for label in examples[\"label\"]]\n",
        "    encodings = tokenizer(\n",
        "        text,\n",
        "        max_length=256,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True\n",
        "    )\n",
        "    encodings[\"labels\"] = labels\n",
        "    return encodings\n",
        "\n",
        "train_dataset = Dataset.from_list(train_data).map(preprocess_function, batched=True)\n",
        "val_dataset = Dataset.from_list(val_data).map(preprocess_function, batched=True)\n",
        "\n",
        "train_dataset = train_dataset.remove_columns([\"text\", \"label\"])\n",
        "val_dataset = val_dataset.remove_columns([\"text\", \"label\"])\n",
        "\n",
        "# ==== مدل با Dropout بیشتر ====\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=NUM_LABELS,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    hidden_dropout_prob=0.3,     # ← افزایش Dropout\n",
        "    attention_probs_dropout_prob=0.3  # ← Dropout در توجه\n",
        ")\n",
        "\n",
        "# ==== تابع متریک ====\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {'accuracy': acc}\n",
        "\n",
        "# ==== تنظیمات آموزش ====\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,  # ← کمک به جلوگیری از overfitting\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    logging_dir=f\"{OUTPUT_DIR}/logs\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    eval_strategy=\"epoch\",  # ← برای EarlyStopping لازم است\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    seed=SEED,\n",
        "    do_eval=True,\n",
        "    load_best_model_at_end=True,  # ← بهترین مدل ذخیره می‌شود\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    greater_is_better=True,\n",
        "    report_to=\"none\",\n",
        "    log_level=\"info\"\n",
        ")\n",
        "\n",
        "# ==== Trainer با EarlyStopping ====\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]  # ← توقف زودهنگام\n",
        ")\n",
        "\n",
        "# ==== آموزش ====\n",
        "print(\"🚀 شروع آموزش مدل...\")\n",
        "trainer.train()\n",
        "\n",
        "# ==== ذخیره بهترین مدل ====\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "trainer.save_model(os.path.join(OUTPUT_DIR, \"best_model\"))\n",
        "print(\"✅ مدل با موفقیت ذخیره شد!\")\n",
        "\n",
        "# ==== ارزیابی ====\n",
        "predictions = trainer.predict(val_dataset)\n",
        "preds = np.argmax(predictions.predictions, axis=1)\n",
        "labels = predictions.label_ids\n",
        "\n",
        "print(\"\\n📊 Classification Report:\")\n",
        "print(classification_report(labels, preds, target_names=labels_list))\n",
        "\n",
        "# ==== Confusion Matrix ====\n",
        "cm = confusion_matrix(labels, preds)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    xticklabels=labels_list_en,\n",
        "    yticklabels=labels_list_en,\n",
        "    cmap=\"Blues\",\n",
        "    linewidths=0.5,\n",
        "    linecolor='gray'\n",
        ")\n",
        "plt.xlabel(\"Predicted\", fontsize=12)\n",
        "plt.ylabel(\"True\", fontsize=12)\n",
        "plt.title(\"Confusion Matrix\", fontsize=14)\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"confusion_matrix.png\"))\n",
        "plt.show()\n",
        "\n",
        "# ==== ذخیره نتایج در JSON ====\n",
        "results_data = {\n",
        "    \"train_loss\": float(trainer.state.log_history[-1].get(\"train_loss\", 0)),\n",
        "    \"val_accuracy\": float(accuracy_score(labels, preds)),\n",
        "    \"classification_report\": classification_report(labels, preds, target_names=labels_list, output_dict=True),\n",
        "    \"confusion_matrix\": cm.tolist(),\n",
        "    \"labels\": labels_list\n",
        "}\n",
        "\n",
        "results_path = os.path.join(OUTPUT_DIR, \"results.json\")\n",
        "with open(results_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(results_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"✅ نتایج در مسیر زیر ذخیره شد: {results_path}\")\n"
      ],
      "metadata": {
        "id": "2oeF7jXFL-xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeQYP4J_cz_3"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KENBKEIEWb2O"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ==== غیرفعال‌سازی W&B ====\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# ==== مسیرها ====\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Final/final-bert-fa-lora/best_model\"\n",
        "TEST_FILE = \"/content/drive/MyDrive/Final/lora_test.json\"\n",
        "\n",
        "# ==== لیبل‌ها (فارسی برای دسته‌بندی) ====\n",
        "labels_list = ['اقتصادی', 'تفریح و نشاط', 'فرهنگ', 'ورزشی']\n",
        "label2id = {label: i for i, label in enumerate(labels_list)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "\n",
        "# ==== بارگذاری مدل ====\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, local_files_only=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_PATH,\n",
        "    local_files_only=True,\n",
        "    num_labels=len(labels_list),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "# ==== بارگذاری داده تست ====\n",
        "with open(TEST_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "test_data_cleaned = [item for item in test_data if item.get(\"label\") in label2id]\n",
        "removed_count = len(test_data) - len(test_data_cleaned)\n",
        "print(f\"⚠️ {removed_count} نمونه حذف شدند به‌دلیل لیبل نادرست یا خالی.\")\n",
        "\n",
        "# ==== پیش‌پردازش ====\n",
        "def preprocess_function(examples):\n",
        "    texts = examples[\"text\"]\n",
        "    labels = [label2id[label] for label in examples[\"label\"]]\n",
        "    encodings = tokenizer(\n",
        "        texts,\n",
        "        max_length=256,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True\n",
        "    )\n",
        "    encodings[\"labels\"] = labels\n",
        "    return encodings\n",
        "\n",
        "test_dataset = Dataset.from_list(test_data_cleaned).map(preprocess_function, batched=True)\n",
        "test_dataset = test_dataset.remove_columns([\"text\", \"label\"])\n",
        "\n",
        "# ==== متریک ====\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {'accuracy': acc}\n",
        "\n",
        "# ==== Trainer ====\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer),\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# ==== ارزیابی ====\n",
        "print(\"🔍 در حال ارزیابی مدل روی داده‌های تست...\")\n",
        "predictions = trainer.predict(test_dataset)\n",
        "preds = np.argmax(predictions.predictions, axis=1)\n",
        "labels = predictions.label_ids\n",
        "metrics = predictions.metrics\n",
        "\n",
        "# ==== نتایج ====\n",
        "print(\"\\n📉 Test Loss:\", round(metrics[\"test_loss\"], 4))\n",
        "print(\"✅ Test Accuracy:\", round(metrics[\"test_accuracy\"], 4))\n",
        "\n",
        "print(\"\\n📊 Classification Report:\")\n",
        "print(classification_report(labels, preds, target_names=labels_list))\n",
        "\n",
        "# ==== Confusion Matrix ====\n",
        "labels_list_en = ['Economic', 'Entertainment', 'Culture', 'Sports']\n",
        "\n",
        "cm = confusion_matrix(labels, preds)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    xticklabels=labels_list_en,\n",
        "    yticklabels=labels_list_en,\n",
        "    cmap=\"YlGnBu\",\n",
        "    linewidths=0.5,\n",
        "    linecolor='gray'\n",
        ")\n",
        "plt.xlabel(\"Predicted Labels\", fontsize=12)\n",
        "plt.ylabel(\"True Labels\", fontsize=12)\n",
        "plt.title(\"Confusion Matrix - Test Set\", fontsize=14)\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvJFFF_AakTw"
      },
      "source": [
        "# Unseen Data(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xh-8VjDUaxYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8994f0c2-d30d-41b0-cbab-9a75de1e9d95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading file chat_template.jinja\n",
            "loading configuration file /content/drive/MyDrive/Final1/final-bert-fa-lora/best_model/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.3,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.3,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"\\u0627\\u0642\\u062a\\u0635\\u0627\\u062f\\u06cc\",\n",
            "    \"1\": \"\\u062a\\u0641\\u0631\\u06cc\\u062d \\u0648 \\u0646\\u0634\\u0627\\u0637\",\n",
            "    \"2\": \"\\u0641\\u0631\\u0647\\u0646\\u06af\",\n",
            "    \"3\": \"\\u0648\\u0631\\u0632\\u0634\\u06cc\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"\\u0627\\u0642\\u062a\\u0635\\u0627\\u062f\\u06cc\": 0,\n",
            "    \"\\u062a\\u0641\\u0631\\u06cc\\u062d \\u0648 \\u0646\\u0634\\u0627\\u0637\": 1,\n",
            "    \"\\u0641\\u0631\\u0647\\u0646\\u06af\": 2,\n",
            "    \"\\u0648\\u0631\\u0632\\u0634\\u06cc\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.53.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 100000\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Final1/final-bert-fa-lora/best_model/model.safetensors\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/Final1/final-bert-fa-lora/best_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔹 یک متن وارد کن (یا 'exit' برای خروج):\n",
            ">  در پی نوسانات شدید بازار ارز و افزایش نرخ دلار در هفته‌های اخیر، بانک مرکزی با اتخاذ سیاست‌های جدیدی تلاش کرده است تا ثبات نسبی را به بازار ارز بازگرداند. در این راستا، عرضه ارز در سامانه نیما افزایش یافته و سقف خرید ارز برای واردکنندگان کاهش یافته است. همچنین، برنامه‌هایی برای مدیریت تقاضای ارز مسافرتی و تجاری در دست اجراست. کارشناسان معتقدند که تنها راهکار بلندمدت برای مهار تورم و کنترل نوسانات ارزی، تقویت تولید داخلی، جذب سرمایه‌گذاری خارجی و افزایش صادرات غیرنفتی است. در همین حال، بخش خصوصی نیز خواستار کاهش موانع تجاری و اصلاح ساختار بانکی برای تسهیل فعالیت‌های اقتصادی شده است.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📝 متن:  در پی نوسانات شدید بازار ارز و افزایش نرخ دلار در هفته‌های اخیر، بانک مرکزی با اتخاذ سیاست‌های جدیدی تلاش کرده است تا ثبات نسبی را به بازار ارز بازگرداند. در این راستا، عرضه ارز در سامانه نیما افزایش یافته و سقف خرید ارز برای واردکنندگان کاهش یافته است. همچنین، برنامه‌هایی برای مدیریت تقاضای ارز مسافرتی و تجاری در دست اجراست. کارشناسان معتقدند که تنها راهکار بلندمدت برای مهار تورم و کنترل نوسانات ارزی، تقویت تولید داخلی، جذب سرمایه‌گذاری خارجی و افزایش صادرات غیرنفتی است. در همین حال، بخش خصوصی نیز خواستار کاهش موانع تجاری و اصلاح ساختار بانکی برای تسهیل فعالیت‌های اقتصادی شده است.\n",
            "📚 برچسب پیش‌بینی‌شده: اقتصادی\n",
            "📊 اعتماد مدل: 99.39%\n",
            "\n",
            "🔹 یک متن وارد کن (یا 'exit' برای خروج):\n",
            ">  در مراسم افتتاحیه سی‌ونهمین جشنواره بین‌المللی فیلم فجر، که با حضور گسترده اهالی سینما، منتقدان و خبرنگاران برگزار شد، آثار شاخصی از سینماگران جوان و باتجربه به نمایش درآمد. امسال با توجه به تغییرات در آیین‌نامه داوری و افزایش تعداد فیلم‌های بخش مسابقه، تنوع بیشتری در ژانرها و سبک‌ها مشاهده می‌شود. همچنین، فیلم‌هایی با رویکرد اجتماعی و پرداختن به مسائل روز جامعه ایرانی بیشتر مورد توجه قرار گرفته‌اند. در حاشیه این مراسم، از چند هنرمند پیشکسوت نیز تقدیر به‌عمل آمد و نشستی با موضوع «سینما و هویت فرهنگی» برگزار شد. برگزارکنندگان جشنواره اعلام کردند که هدف امسال، تقویت تعامل فرهنگی با سینماهای منطقه و حمایت از تولیدات مستقل داخلی است.\n",
            "\n",
            "📝 متن:  در مراسم افتتاحیه سی‌ونهمین جشنواره بین‌المللی فیلم فجر، که با حضور گسترده اهالی سینما، منتقدان و خبرنگاران برگزار شد، آثار شاخصی از سینماگران جوان و باتجربه به نمایش درآمد. امسال با توجه به تغییرات در آیین‌نامه داوری و افزایش تعداد فیلم‌های بخش مسابقه، تنوع بیشتری در ژانرها و سبک‌ها مشاهده می‌شود. همچنین، فیلم‌هایی با رویکرد اجتماعی و پرداختن به مسائل روز جامعه ایرانی بیشتر مورد توجه قرار گرفته‌اند. در حاشیه این مراسم، از چند هنرمند پیشکسوت نیز تقدیر به‌عمل آمد و نشستی با موضوع «سینما و هویت فرهنگی» برگزار شد. برگزارکنندگان جشنواره اعلام کردند که هدف امسال، تقویت تعامل فرهنگی با سینماهای منطقه و حمایت از تولیدات مستقل داخلی است.\n",
            "📚 برچسب پیش‌بینی‌شده: تفریح و نشاط\n",
            "📊 اعتماد مدل: 96.23%\n",
            "\n",
            "🔹 یک متن وارد کن (یا 'exit' برای خروج):\n",
            ">  تیم ملی والیبال ایران در چهارمین دیدار خود از مرحله گروهی رقابت‌های لیگ ملت‌های ۲۰۲۵ به مصاف تیم قدرتمند ایتالیا رفت. این بازی که در سالن المپیک توکیو برگزار شد، با حضور پرشور تماشاگران و پخش زنده از چند شبکه تلویزیونی همراه بود. والیبالیست‌های ایرانی با بازی هماهنگ و دفاع منسجم، موفق شدند ست اول را با اختلاف امتیاز بالا به‌نفع خود به پایان برسانند. هرچند تیم ایتالیا در ست دوم بازگشتی قدرتمند داشت، اما در نهایت ایران با درخشش سعید معروف و امیر غفور، بازی را در ست پنجم با نتیجه ۳ بر ۲ به سود خود تمام کرد. سرمربی تیم ایران در پایان مسابقه از تعهد و انگیزه بازیکنانش تمجید کرد و وعده داد تیم با قدرت بیشتری در ادامه رقابت‌ها حاضر خواهد شد.\n",
            "\n",
            "📝 متن:  تیم ملی والیبال ایران در چهارمین دیدار خود از مرحله گروهی رقابت‌های لیگ ملت‌های ۲۰۲۵ به مصاف تیم قدرتمند ایتالیا رفت. این بازی که در سالن المپیک توکیو برگزار شد، با حضور پرشور تماشاگران و پخش زنده از چند شبکه تلویزیونی همراه بود. والیبالیست‌های ایرانی با بازی هماهنگ و دفاع منسجم، موفق شدند ست اول را با اختلاف امتیاز بالا به‌نفع خود به پایان برسانند. هرچند تیم ایتالیا در ست دوم بازگشتی قدرتمند داشت، اما در نهایت ایران با درخشش سعید معروف و امیر غفور، بازی را در ست پنجم با نتیجه ۳ بر ۲ به سود خود تمام کرد. سرمربی تیم ایران در پایان مسابقه از تعهد و انگیزه بازیکنانش تمجید کرد و وعده داد تیم با قدرت بیشتری در ادامه رقابت‌ها حاضر خواهد شد.\n",
            "📚 برچسب پیش‌بینی‌شده: ورزشی\n",
            "📊 اعتماد مدل: 99.96%\n",
            "\n",
            "🔹 یک متن وارد کن (یا 'exit' برای خروج):\n",
            ">  در آستانه فصل تابستان، نمایشگاه گردشگری و صنایع‌دستی تهران با استقبال گسترده بازدیدکنندگان آغاز به‌کار کرد. در این نمایشگاه، استان‌های مختلف کشور با ارائه غرفه‌هایی متنوع، جاذبه‌های گردشگری، آیین‌های سنتی، غذاهای محلی و تولیدات صنایع‌دستی خود را معرفی کردند. یکی از بخش‌های جذاب نمایشگاه، اجرای زنده موسیقی نواحی، کارگاه‌های آموزشی سفال‌گری، فرش‌بافی و ساخت زیورآلات سنتی بود که توانست توجه خانواده‌ها و گردشگران را به خود جلب کند. مسئولان برگزارکننده هدف این رویداد را ترویج گردشگری داخلی، حمایت از مشاغل بومی و تقویت اقتصاد گردشگری اعلام کردند. همچنین، بسته‌های سفر تخفیفی نیز توسط آژانس‌های مسافرتی در اختیار بازدیدکنندگان قرار گرفت.\n",
            "\n",
            "📝 متن:  در آستانه فصل تابستان، نمایشگاه گردشگری و صنایع‌دستی تهران با استقبال گسترده بازدیدکنندگان آغاز به‌کار کرد. در این نمایشگاه، استان‌های مختلف کشور با ارائه غرفه‌هایی متنوع، جاذبه‌های گردشگری، آیین‌های سنتی، غذاهای محلی و تولیدات صنایع‌دستی خود را معرفی کردند. یکی از بخش‌های جذاب نمایشگاه، اجرای زنده موسیقی نواحی، کارگاه‌های آموزشی سفال‌گری، فرش‌بافی و ساخت زیورآلات سنتی بود که توانست توجه خانواده‌ها و گردشگران را به خود جلب کند. مسئولان برگزارکننده هدف این رویداد را ترویج گردشگری داخلی، حمایت از مشاغل بومی و تقویت اقتصاد گردشگری اعلام کردند. همچنین، بسته‌های سفر تخفیفی نیز توسط آژانس‌های مسافرتی در اختیار بازدیدکنندگان قرار گرفت.\n",
            "📚 برچسب پیش‌بینی‌شده: تفریح و نشاط\n",
            "📊 اعتماد مدل: 99.63%\n",
            "\n",
            "🔹 یک متن وارد کن (یا 'exit' برای خروج):\n",
            "> exit\n"
          ]
        }
      ],
      "source": [
        "model_path = \"/content/drive/MyDrive/Final1/final-bert-fa-lora/best_model\"\n",
        "\n",
        "# ===== بارگذاری مدل و توکنایزر =====\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "\n",
        "label_names = [\"اقتصادی\", \"تفریح و نشاط\", \"فرهنگ\", \"ورزشی\"]\n",
        "\n",
        "# ===== تابع پیش‌بینی =====\n",
        "def classify_text(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        pred_class = torch.argmax(probs, dim=-1).item()\n",
        "        confidence = probs[0][pred_class].item()\n",
        "\n",
        "    print(f\"\\n📝 متن: {text}\")\n",
        "    print(f\"📚 برچسب پیش‌بینی‌شده: {label_names[pred_class]}\")\n",
        "    print(f\"📊 اعتماد مدل: {confidence:.2%}\")\n",
        "\n",
        "# ===== تست با یک ورودی دلخواه =====\n",
        "while True:\n",
        "    user_input = input(\"\\n🔹 یک متن وارد کن (یا 'exit' برای خروج):\\n> \")\n",
        "    if user_input.strip().lower() == \"exit\":\n",
        "        break\n",
        "    classify_text(user_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "0HbDREDDPl2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/MyDrive/Final1/final-bert-fa-lora/best_model\"\n",
        "\n",
        "# ===== بارگذاری مدل و توکنایزر =====\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "\n",
        "label_names = [\"اقتصادی\", \"تفریح و نشاط\", \"فرهنگ\", \"ورزشی\"]\n",
        "\n",
        "# ===== تابع پیش‌بینی =====\n",
        "def classify_text(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        pred_class = torch.argmax(probs, dim=-1).item()\n",
        "        confidence = probs[0][pred_class].item()\n",
        "\n",
        "    print(f\"\\n📝 متن: {text}\")\n",
        "    print(f\"📚 برچسب پیش‌بینی‌شده: {label_names[pred_class]}\")\n",
        "    print(f\"📊 اعتماد مدل: {confidence:.2%}\")\n",
        "\n",
        "# ===== تست با یک ورودی دلخواه =====\n",
        "while True:\n",
        "    user_input = input(\"\\n🔹 یک متن وارد کن (یا 'exit' برای خروج):\\n> \")\n",
        "    if user_input.strip().lower() == \"exit\":\n",
        "        break\n",
        "    classify_text(user_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAnZMzwUPmlo",
        "outputId": "7fff6cbc-e2f9-4176-d6bf-83214f047e1d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading file chat_template.jinja\n",
            "loading configuration file /content/drive/MyDrive/Final1/final-bert-fa-lora/best_model/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.3,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.3,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"\\u0627\\u0642\\u062a\\u0635\\u0627\\u062f\\u06cc\",\n",
            "    \"1\": \"\\u062a\\u0641\\u0631\\u06cc\\u062d \\u0648 \\u0646\\u0634\\u0627\\u0637\",\n",
            "    \"2\": \"\\u0641\\u0631\\u0647\\u0646\\u06af\",\n",
            "    \"3\": \"\\u0648\\u0631\\u0632\\u0634\\u06cc\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"\\u0627\\u0642\\u062a\\u0635\\u0627\\u062f\\u06cc\": 0,\n",
            "    \"\\u062a\\u0641\\u0631\\u06cc\\u062d \\u0648 \\u0646\\u0634\\u0627\\u0637\": 1,\n",
            "    \"\\u0641\\u0631\\u0647\\u0646\\u06af\": 2,\n",
            "    \"\\u0648\\u0631\\u0632\\u0634\\u06cc\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.53.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 100000\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Final1/final-bert-fa-lora/best_model/model.safetensors\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/Final1/final-bert-fa-lora/best_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔹 یک متن وارد کن (یا 'exit' برای خروج):\n",
            "> نساجی مازندران در فصل جدید لیگ دسته اول تیمی پرمهره خواهد بود که برای بازگشت سریع به لیگ‌برتر تلاش می‌کند. اگرچه نساجی هنوز به‌صورت رسمی فراز کمالوند را به‌عنوان سرمربی اعلام نکرده، اما مدیران باشگاه با او به توافق نزدیک هستند و مذاکره برای جذب بازیکنان سرشناس را آغاز کرده‌اند. در روزهای اخیر، باشگاه تمرینات را در مازندران برگزار کرده و فعالیت‌های خود را برای تقویت تیم با جذب ستاره‌های لیگ‌برتر آغاز کرده است. مدیران باشگاه قصد دارند تیمی قدرتمند و پرمهره راه‌اندازی کنند تا نه‌تنها رضایت هواداران را جلب کنند،‌ بلکه با قرار گرفتن بین دو تیم برتر لیگ‌یک، بلافاصله به لیگ‌برتر بازگردند. طبق پیش‌بینی‌ها، در آینده‌ای نزدیک شاهد رونمایی رسمی باشگاه از چند بازیکن جدید و باتجربه خواهیم بود.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📝 متن: نساجی مازندران در فصل جدید لیگ دسته اول تیمی پرمهره خواهد بود که برای بازگشت سریع به لیگ‌برتر تلاش می‌کند. اگرچه نساجی هنوز به‌صورت رسمی فراز کمالوند را به‌عنوان سرمربی اعلام نکرده، اما مدیران باشگاه با او به توافق نزدیک هستند و مذاکره برای جذب بازیکنان سرشناس را آغاز کرده‌اند. در روزهای اخیر، باشگاه تمرینات را در مازندران برگزار کرده و فعالیت‌های خود را برای تقویت تیم با جذب ستاره‌های لیگ‌برتر آغاز کرده است. مدیران باشگاه قصد دارند تیمی قدرتمند و پرمهره راه‌اندازی کنند تا نه‌تنها رضایت هواداران را جلب کنند،‌ بلکه با قرار گرفتن بین دو تیم برتر لیگ‌یک، بلافاصله به لیگ‌برتر بازگردند. طبق پیش‌بینی‌ها، در آینده‌ای نزدیک شاهد رونمایی رسمی باشگاه از چند بازیکن جدید و باتجربه خواهیم بود.\n",
            "📚 برچسب پیش‌بینی‌شده: ورزشی\n",
            "📊 اعتماد مدل: 99.94%\n",
            "\n",
            "🔹 یک متن وارد کن (یا 'exit' برای خروج):\n",
            "> بر اساس گزارش رسمی خبرگزاری تسنیم، در خرداد ماه ۱۴۰۴ میزان عرضه گوشت قرمز در کشتارگاه‌های کشور حدود ۱۵ درصد نسبت به اردیبهشت ماه افزایش یافته است. این افزایش عرضه به‌عنوان یک شاخص مثبت در حوزه اقتصاد مواد غذایی کشور ارزیابی می‌شود. وزارت جهاد کشاورزی اعلام کرده که این رشد ناشی از تقویت واردات دام، به‌کارگیری ظرفیت‌های بلااستفاده کشتارگاه‌ها و همچنین سیاست‌های تشویقی برای دامداران در جهت عرضه مستقیم تولیدات بوده است. با افزایش عرضه رسمی، انتظار می‌رود فشار قیمتی در بازار کاهش یابد و از نوسانات شدید جلوگیری شود. این روند همچنین می‌تواند نقش مهمی در کنترل تورم غذایی ایفا کند، به‌ویژه در ماه‌های گرم سال که مصرف خانوارها افزایش می‌یابد. از سوی دیگر، جلوگیری از قاچاق دام زنده به‌عنوان یکی از اهداف کلان اقتصادی دولت مطرح شده و عرضه بیشتر در بازار داخلی می‌تواند به تحقق این هدف نیز کمک کند. در مجموع، سیاست‌گذاران امیدوارند این افزایش پایدار باشد و به ایجاد تعادل بین تولید، عرضه و تقاضا در زنجیره تامین گوشت کشور منجر شود.\n",
            "\n",
            "📝 متن: بر اساس گزارش رسمی خبرگزاری تسنیم، در خرداد ماه ۱۴۰۴ میزان عرضه گوشت قرمز در کشتارگاه‌های کشور حدود ۱۵ درصد نسبت به اردیبهشت ماه افزایش یافته است. این افزایش عرضه به‌عنوان یک شاخص مثبت در حوزه اقتصاد مواد غذایی کشور ارزیابی می‌شود. وزارت جهاد کشاورزی اعلام کرده که این رشد ناشی از تقویت واردات دام، به‌کارگیری ظرفیت‌های بلااستفاده کشتارگاه‌ها و همچنین سیاست‌های تشویقی برای دامداران در جهت عرضه مستقیم تولیدات بوده است. با افزایش عرضه رسمی، انتظار می‌رود فشار قیمتی در بازار کاهش یابد و از نوسانات شدید جلوگیری شود. این روند همچنین می‌تواند نقش مهمی در کنترل تورم غذایی ایفا کند، به‌ویژه در ماه‌های گرم سال که مصرف خانوارها افزایش می‌یابد. از سوی دیگر، جلوگیری از قاچاق دام زنده به‌عنوان یکی از اهداف کلان اقتصادی دولت مطرح شده و عرضه بیشتر در بازار داخلی می‌تواند به تحقق این هدف نیز کمک کند. در مجموع، سیاست‌گذاران امیدوارند این افزایش پایدار باشد و به ایجاد تعادل بین تولید، عرضه و تقاضا در زنجیره تامین گوشت کشور منجر شود.\n",
            "📚 برچسب پیش‌بینی‌شده: اقتصادی\n",
            "📊 اعتماد مدل: 99.85%\n",
            "\n",
            "🔹 یک متن وارد کن (یا 'exit' برای خروج):\n",
            "> در استان قزوین همزمان با برگزاری پیاده‌روی بزرگ خانوادگی، جمع بسیاری از شهروندان در میان کوه‌ها و طبیعت منطقه حاضر شدند تا علاوه بر ورزش روزانه، فرهنگ گردشگری و همبستگی اجتماعی را نیز تقویت کنند. این رویداد مردمی با هدف افزایش سطح سلامت جسمانی و روحی خانواده‌ها برنامه‌ریزی شده بود.  بر خلاف دیدگاه سنتی، این جشنواره با حضور قشرهای مختلف جامعه – از جمله کودکان، نوجوانان، والدین و حتی سالمندان – توانست فضایی ایجاد کند که افراد علاوه بر طبیعت‌گردی، فرصتی برای آشنایی و تبادل فرهنگی نیز پیدا کنند. مدیران شهری قزوین تأکید کردند که این برنامه علاوه بر ایجاد شور اجتماعی، بستری مناسب برای معرفی ظرفیت‌های فرهنگی و گردشگری استان محسوب می‌شود.  در پایان اجرای پیاده‌روی، از دو ورزشکار پاراکاراته‌کار منتخب قزوین، لیلا چالیان و محمد جعفری، تقدیر شد تا ضمن اهمیت دادن به ورزش معلولان، جلوه‌ای از نشاط تیمی نیز در رویداد دیده شود. این اقدام باعث شد جشنواره به یک رویداد جامع با ترکیب ورزش، تفریح، فرهنگ و همبستگی اجتماعی تبدیل شود\n",
            "\n",
            "📝 متن: در استان قزوین همزمان با برگزاری پیاده‌روی بزرگ خانوادگی، جمع بسیاری از شهروندان در میان کوه‌ها و طبیعت منطقه حاضر شدند تا علاوه بر ورزش روزانه، فرهنگ گردشگری و همبستگی اجتماعی را نیز تقویت کنند. این رویداد مردمی با هدف افزایش سطح سلامت جسمانی و روحی خانواده‌ها برنامه‌ریزی شده بود.  بر خلاف دیدگاه سنتی، این جشنواره با حضور قشرهای مختلف جامعه – از جمله کودکان، نوجوانان، والدین و حتی سالمندان – توانست فضایی ایجاد کند که افراد علاوه بر طبیعت‌گردی، فرصتی برای آشنایی و تبادل فرهنگی نیز پیدا کنند. مدیران شهری قزوین تأکید کردند که این برنامه علاوه بر ایجاد شور اجتماعی، بستری مناسب برای معرفی ظرفیت‌های فرهنگی و گردشگری استان محسوب می‌شود.  در پایان اجرای پیاده‌روی، از دو ورزشکار پاراکاراته‌کار منتخب قزوین، لیلا چالیان و محمد جعفری، تقدیر شد تا ضمن اهمیت دادن به ورزش معلولان، جلوه‌ای از نشاط تیمی نیز در رویداد دیده شود. این اقدام باعث شد جشنواره به یک رویداد جامع با ترکیب ورزش، تفریح، فرهنگ و همبستگی اجتماعی تبدیل شود\n",
            "📚 برچسب پیش‌بینی‌شده: تفریح و نشاط\n",
            "📊 اعتماد مدل: 99.18%\n",
            "\n",
            "🔹 یک متن وارد کن (یا 'exit' برای خروج):\n",
            "> exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TpJQRoFNPob1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}